<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Hossein Taheri</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
  body {
    font-family: Arial, sans-serif;
    max-width: 900px;
    margin: auto;
    padding: 20px;
    line-height: 1.6;
  }
  h1, h2 {
    color: #333;
  }
  a {
    color: #0645AD;
    text-decoration: none;
  }
  a:hover {
    text-decoration: underline;
  }
  .section {
    margin-top: 40px;
  }
</style>
</head>

<body>

<h1><strong>Hossein Taheri</strong></h1>

<p>
Postdoctoral Scholar, Computer Science & Engineering<br>
University of California, San Diego<br>
Email: <a href="mailto:htaheri@ucsd.edu">htaheri@ucsd.edu</a><br>
Phone: +1 (805) 689-6439<br>
<a href="https://www.linkedin.com/in/hossein-taheri-86386922a/">LinkedIn</a> |
<a href="https://scholar.google.com/citations?user=J_MeH1gAAAAJ&hl=en&oi=sra">Google Scholar</a>
</p>

<div class="section">
<h2>Research Overview</h2>
<p>
My research focuses on understanding and advancing learning algorithms and models through
both statistical and computational lenses. I work on linear models, neural networks,
and transformers, with an emphasis on theoretical foundations and practical performance.
My projects have been published in ICML, JMLR, NeurIPS, AISTATS, AAAI, TMLR, TNNLS, and ICLR.
</p>
</div>

<div class="section">
<h2>Research Interests</h2>
<ul>
  <li>Theoretical Foundations of Deep Learning</li>
  <li>Generalization and Optimization in Neural Networks</li>
  <li>Transformers and Attention Models</li>
  <li>Continual / Lifelong Learning</li>
  <li>High-dimensional Statistics</li>
  <li>Distributed and Decentralized Optimization</li>
  <li>Adversarial Robustness & Classification Theory</li>
</ul>
</div>

<div class="section">
<h2>Selected Publications</h2>

<ol>
  <li>
    <strong>On the Theory of Continual Learning with Gradient Descent for Neural Networks</strong><br>
    H. Taheri, A. Ghosh, A. Mazumdar.<br>
    Working paper, arXiv 2025.<br>
    <a href="https://arxiv.org/abs/XXXX.XXXXX">[Link]</a> <!-- Replace when available -->
  </li>

  <li>
    <strong>Sharper Guarantees for Learning Neural Network Classifiers with Gradient Methods</strong><br>
    H. Taheri, C. Thrampoulidis, A. Mazumdar.<br>
    ICLR 2025.<br>
    <a href="https://openreview.net/">[Link]</a>
  </li>

  <li>
    <strong>Generalization and Stability of Interpolating Neural Networks with Minimal Width</strong><br>
    H. Taheri, C. Thrampoulidis.<br>
    JMLR, 2024.<br>
    <a href="https://www.jmlr.org/">[Link]</a>
  </li>

  <li>
    <strong>On the Optimization and Generalization of Multi-head Attention</strong><br>
    P. Deora*, R. Ghaderi*, H. Taheri*, C. Thrampoulidis.<br>
    TMLR, selected for ICLR 2025 poster.<br>
    <a href="https://jmlr.org/tmlr/">[Link]</a>
  </li>

  <li>
    <strong>On Generalization of Decentralized Learning with Separable Data</strong><br>
    H. Taheri, C. Thrampoulidis.<br>
    AISTATS 2023.<br>
    <a href="https://proceedings.mlr.press/">[Link]</a>
  </li>

  <li>
    <strong>Fast Convergence in Learning Two-layer Neural Networks with Separable Data</strong><br>
    H. Taheri, C. Thrampoulidis.<br>
    AAAI 2023.<br>
    <a href="https://aaai.org/">[Link]</a>
  </li>

  <li>
    <strong>Asymptotic Behavior of Adversarial Training in Binary Linear Classification</strong><br>
    H. Taheri, R. Pedarsani, C. Thrampoulidis.<br>
    IEEE TNNLS, 2023.<br>
    <a href="https://ieeexplore.ieee.org/">[Link]</a>
  </li>

  <li>
    <strong>Fundamental Limits of Ridge-Regularized ERM in High Dimensions</strong><br>
    H. Taheri, R. Pedarsani, C. Thrampoulidis.<br>
    AISTATS 2021.<br>
    <a href="https://proceedings.mlr.press/">[Link]</a>
  </li>

  <li>
    <strong>Quantized Decentralized Stochastic Learning over Directed Graphs</strong><br>
    H. Taheri, A. Mokhtari, H. Hassani, R. Pedarsani.<br>
    ICML 2020.<br>
    <a href="https://proceedings.mlr.press/">[Link]</a>
  </li>
</ol>
</div>

<div class="section">
<h2>Teaching & Mentoring</h2>
<p>
Instructor for DSC 212 â€“ Probability and Statistics for Data Science (UC San Diego).<br>
Mentor to Ph.D. students: Yilan Chen, Harsh Vardhan, Heng Zhu.
</p>
</div>

<div class="section">
<h2>Contact</h2>
<p>
Atkinson Hall, UC San Diego<br>
9500 Gilman Dr, La Jolla, CA 92093
</p>
</div>

</body>
</html>
