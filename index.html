<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Hossein Taheri â€” Academic Website</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
  body { font-family: Arial, sans-serif; max-width: 900px; margin:auto; padding:20px; line-height:1.6; }
  h1, h2 { color:#333; }
  a { color:#0645AD; text-decoration:none; }
  a:hover { text-decoration:underline; }
  .section { margin-top:40px; }
</style>
</head>

<body>

<h1><strong>Hossein Taheri</strong></h1>

<p>
Postdoctoral Scholar, Computer Science & Engineering<br>
University of California, San Diego<br>
Email: <a href="mailto:htaheri@ucsd.edu">htaheri[at]ucsd[dot]edu</a><br>
<a href="https://scholar.google.com/citations?user=J_MeH1gAAAAJ&hl=en">Google Scholar</a> 
</p>

<div class="section">
<h2>Bio</h2>
<p>
I am a Postdoctoral Scholar in the Department of Computer Science and Engineering at UC San Diego, 
advised by <a href="https://mazumdar.ucsd.edu/" target="_blank">Prof. Arya Mazumdar</a>. 
Previously, I obtained my Ph.D. in Electrical and Computer Engineering from UC Santa Barbara, 
where I was advised by 
<a href="https://sites.google.com/view/cthrampo" target="_blank">Prof. Christos Thrampoulidis</a>.
</p>
</div>

<div class="section">
<h2>Research Interests</h2>
<ul>
  <li>Theory of Deep Learning</li>
  <li>Generalization and Optimization of Neural Networks</li>
  <li>Transformers & Multi-head Attention</li>
  <li>Continual / Lifelong Learning</li>
  <li>Distributed & Decentralized Optimization</li>
  <li>High-dimensional Statistics</li>
  <li>Adversarial Robustness</li>
</ul>
</div>

<div class="section">
<h2>Publications</h2>
<ol>

  <li>
    <strong>On the Theory of Continual Learning with Gradient Descent for Neural Networks</strong><br>
    H. Taheri, A. Ghosh, A. Mazumdar (2025).<br>
    <a href="https://arxiv.org/abs/2501.01234">arXiv</a>
  </li>

  <li>
    <strong>Sharper Guarantees for Learning Neural Network Classifiers with Gradient Methods</strong><br>
    H. Taheri, C. Thrampoulidis, A. Mazumdar (ICLR 2025).<br>
    <a href="https://openreview.net/forum?id=by8J59hZxy">OpenReview</a>
  </li>

  <li>
    <strong>Generalization and Stability of Interpolating Neural Networks with Minimal Width</strong><br>
    H. Taheri, C. Thrampoulidis (JMLR 2024).<br>
    <a href="https://www.jmlr.org/papers/v25/23-0422.html">JMLR</a> | 
    <a href="https://arxiv.org/abs/2302.09235">arXiv</a>
  </li>

  <li>
    <strong>On the Optimization and Generalization of Multi-head Attention</strong><br>
    P. Deora*, R. Ghaderi*, H. Taheri*, C. Thrampoulidis (TMLR 2024, ICLR poster).<br>
    <a href="https://openreview.net/forum?id=4CVi0tEo5p">OpenReview</a>
  </li>

  <li>
    <strong>On Generalization of Decentralized Learning with Separable Data</strong><br>
    H. Taheri, C. Thrampoulidis (AISTATS 2023).<br>
    <a href="https://proceedings.mlr.press/v206/taheri23a.html">PMLR</a>
  </li>

  <li>
    <strong>Fast Convergence in Learning Two-layer Neural Networks with Separable Data</strong><br>
    H. Taheri, C. Thrampoulidis (AAAI 2023).<br>
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26320">AAAI</a>
  </li>

  <li>
    <strong>Asymptotic Behavior of Adversarial Training in Binary Linear Classification</strong><br>
    H. Taheri, R. Pedarsani, C. Thrampoulidis (IEEE TNNLS 2023).<br>
    <a href="https://ieeexplore.ieee.org/document/10165456">IEEE</a> |
    <a href="https://arxiv.org/abs/2010.13275">arXiv</a>
  </li>

  <li>
    <strong>Fundamental Limits of Ridge-Regularized Empirical Risk Minimization in High Dimensions</strong><br>
    H. Taheri, R. Pedarsani, C. Thrampoulidis (AISTATS 2021).<br>
    <a href="https://proceedings.mlr.press/v130/taheri21a.html">PMLR</a>
  </li>

  <li>
    <strong>Quantized Decentralized Stochastic Learning over Directed Graphs</strong><br>
    H. Taheri, A. Mokhtari, H. Hassani, R. Pedarsani (ICML 2020).<br>
    <a href="https://proceedings.mlr.press/v119/taheri20a.html">PMLR</a>
  </li>

  <li>
    <strong>Sharp Asymptotics and Optimal Performance for Inference in Binary Models</strong><br>
    H. Taheri, R. Pedarsani, C. Thrampoulidis (AISTATS 2020).<br>
    <a href="https://proceedings.mlr.press/v108/taheri20a.html">PMLR</a>
  </li>

  <li>
    <strong>Optimality of Least-Squares for Classification in Gaussian Mixture Models</strong><br>
    H. Taheri, R. Pedarsani, C. Thrampoulidis (ISIT 2020).<br>
    <a href="https://ieeexplore.ieee.org/document/9174216">IEEE</a>
  </li>

  <li>
    <strong>Robust and Communication-efficient Collaborative Learning</strong><br>
    A. Reisizadeh, H. Taheri, A. Mokhtari, H. Hassani, R. Pedarsani (NeurIPS 2019).<br>
    <a href="https://papers.nips.cc/paper/2019/hash/0b05d4c1d07e14f3bdb7a0455e1c7a6b-Abstract.html">NeurIPS</a>
  </li>

</ol>
</div>

</body>
</html>
